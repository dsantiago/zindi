{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissão básica\n",
    "\n",
    "- Neste notebook vamos criar uma submissão <strong>baseline</strong>, que é uma submissão inicial sem muita análise e processamento.\n",
    "- A ideia é entender como treinar um modelo simples com os dados e criar uma submissão válida, que será nosso ponto de partida a ser superado.\n",
    "- Também serve para verificar se nossa validação local está semelhante à pontuação na competição. Como a quantidade de submissões ao longo da competição é limitada em 300, o ideal é passarmos a maior parte do tempo validando os experimentos localmente.\n",
    "- Ou seja, é esencial que a acurácia obtida na validação local se aproxime da acurácia do leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 3), (30000, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treino, teste e modelo de submissão\n",
    "train = pd.read_csv('data/Train.csv')\n",
    "test = pd.read_csv('data/Test.csv')\n",
    "sub = pd.read_csv('data/SampleSubmission.csv')\n",
    "\n",
    "# Parece que os IDs do modelo de submissão estão fora de ordem\n",
    "# então substituímos eles pela ordem do arquivo de teste\n",
    "sub.ID = test.ID\n",
    "\n",
    "# Target a ser previsto o treino\n",
    "target = train['label']\n",
    "\n",
    "# Dimensões dos dataframes de treino e teste\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    38239\n",
       "-1    29295\n",
       " 0     2466\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribuição dos targets\n",
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w       19465\n",
       "ya       8961\n",
       "fi       8837\n",
       "el       7808\n",
       "slim     7103\n",
       "rabi     6477\n",
       "si       3631\n",
       "ca       3144\n",
       "l        3107\n",
       "kol      3093\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = train.text.str.split(' ').explode()\n",
    "words.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPWORDS: ['w', 'ya', 'fi', 'el', 'slim', 'rabi']\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 5000\n",
    "stop_words = words.value_counts()[words.value_counts() > THRESHOLD].index.tolist()\n",
    "\n",
    "print('STOPWORDS:', stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13P0QT0</td>\n",
       "      <td>3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKCLXCJ</td>\n",
       "      <td>cha3eb fey9elkoum menghir ta7ayoul ou kressi</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1TVXIJ</td>\n",
       "      <td>bereau degage nathef ya slim walahi ya7chiw fi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0TTYY8</td>\n",
       "      <td>ak slouma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68DX797</td>\n",
       "      <td>entom titmanou lina a7na 3iid moubarik a7na ch...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  label\n",
       "0  13P0QT0  3sbaaaaaaaaaaaaaaaaaaaa lek ou le seim riahi o...     -1\n",
       "1  SKCLXCJ       cha3eb fey9elkoum menghir ta7ayoul ou kressi     -1\n",
       "2  V1TVXIJ  bereau degage nathef ya slim walahi ya7chiw fi...     -1\n",
       "3  U0TTYY8                                          ak slouma      1\n",
       "4  68DX797  entom titmanou lina a7na 3iid moubarik a7na ch...     -1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento básico\n",
    "def preprocess(txt):   \n",
    "    txt = re.sub(r' +', ' ', txt)\n",
    "    txt = txt.lower()\n",
    "    return txt\n",
    "\n",
    "def remove_sw(corpus, stop_words):\n",
    "    corpus = corpus.apply(lambda x: [e for e in x.split(' ') if e not in stop_words])\n",
    "    corpus = corpus.str.join(' ')\n",
    "    return corpus\n",
    "\n",
    "train['txt_ok'] = train.text.apply(preprocess)\n",
    "test['txt_ok'] = test.text.apply(preprocess)\n",
    "\n",
    "REMOVE_STOPWORDS = True\n",
    "# REMOVE_STOPWORDS = False\n",
    "\n",
    "if REMOVE_STOPWORDS:\n",
    "    train['txt_ok'] = remove_sw(train['txt_ok'], stop_words=stop_words)\n",
    "    test['txt_ok'] = remove_sw(test['txt_ok'], stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo o conjunto de textos\n",
    "corpus = pd.concat([train.txt_ok, test.txt_ok], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetorização: transformação dos textos em uma matriz numérica\n",
    "# de documentos x termos.\n",
    "vec = TfidfVectorizer(ngram_range=(1, 6), sublinear_tf=True)\n",
    "vec.fit(corpus)\n",
    "train_vec = vec.transform(train['txt_ok'])\n",
    "test_vec = vec.transform(test['txt_ok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 3097846)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repare que a matriz gerada é esparsa, o que permite lidar\n",
    "# com as 189093 colunas sem ocupar muita memória\n",
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.0s remaining:    9.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78429 0.78614 0.78579 0.78629 0.78921]\n",
      "Mean:  0.7863428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Validação cruzada estratificada 5-folds com um modelo linear\n",
    "m = LinearSVC(max_iter=2000, random_state=42)\n",
    "\n",
    "s = cross_val_score(\n",
    "    m,\n",
    "    train_vec, \n",
    "    target, \n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Média das 5 validações\n",
    "print(np.round(s, 5))\n",
    "print('Mean: ', np.mean(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.0s remaining:    3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76171 0.75793 0.75714 0.76071 0.76193]\n",
      "Mean:  0.7598857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "m = SGDClassifier(loss='log', penalty='l2', class_weight='balanced', tol=0.001, random_state=42)\n",
    "\n",
    "s = cross_val_score(\n",
    "    m,\n",
    "    train_vec, \n",
    "    target, \n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Média das 5 validações\n",
    "print(np.round(s, 5))\n",
    "print('Mean: ', np.mean(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  3.3min remaining:  4.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59779 0.59893 0.595   0.59636 0.59943]\n",
      "Mean:  0.5974999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Validação cruzada estratificada 5-folds com um modelo linear\n",
    "# m = LogisticRegressionCV(random_state=42, tol=0.1, solver='sag', multi_class='multinomial', n_jobs=-1, verbose=1)\n",
    "m2 = LogisticRegression(random_state=42, multi_class='multinomial', n_jobs=-1)\n",
    "\n",
    "s = cross_val_score(\n",
    "    m2,\n",
    "    train_vec, \n",
    "    target, \n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Média das 5 validações\n",
    "print(np.round(s, 5))\n",
    "print('Mean: ', np.mean(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2DDHQW9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5HY6UEY</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATNVUJX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9XYVOQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOAHLRH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>NHXTL3R</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>U1YWB2O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>O3KYLM0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>W4C38TY</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>4NNX5QE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  label\n",
       "0      2DDHQW9      1\n",
       "1      5HY6UEY     -1\n",
       "2      ATNVUJX      1\n",
       "3      Q9XYVOQ      1\n",
       "4      TOAHLRH      1\n",
       "...        ...    ...\n",
       "29995  NHXTL3R     -1\n",
       "29996  U1YWB2O      1\n",
       "29997  O3KYLM0      1\n",
       "29998  W4C38TY     -1\n",
       "29999  4NNX5QE      1\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treina com todos os dados e gera uma submissão\n",
    "m.fit(train_vec, target)\n",
    "\n",
    "sub.label = m.predict(test_vec)\n",
    "\n",
    "sub.to_csv('sub.csv', index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 500000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec.todense().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (layer1): Linear(in_features=500000, out_features=512, bias=True)\n",
      "  (layer2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(num_feature, 512)\n",
    "        self.layer2 = nn.Linear(512, 128)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "    \n",
    "model = MulticlassClassification(num_feature=train_vec.todense().shape[1], num_class=3)\n",
    "# model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #weight=[class_weights].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparsetensor(x):\n",
    "\n",
    "    coo = x.tocoo()\n",
    "    indices = np.vstack((coo.row, coo.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(coo.data)\n",
    "    shape = coo.shape\n",
    "\n",
    "    tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_sparsetensor(test_vec).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[    0,     0,     0,  ...,   127,   127,   127],\n",
      "                       [74857, 74797, 70861,  ...,  6874,  4905,  2457]]),\n",
      "       values=tensor([0.3395, 0.1640, 0.3130,  ..., 0.4038, 0.3857, 0.1838]),\n",
      "       size=(128, 100000), nnz=1525, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=to_sparsetensor(train_vec), batch_size=128) #, sampler=weighted_sampler)\n",
    "val_loader = DataLoader(dataset=to_sparsetensor(test_vec), batch_size=1)\n",
    "test_loader = DataLoader(dataset=to_sparsetensor(test_vec), batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 320175.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'zip' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-28e0f51a04ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mX_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'zip' has no len()"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "EPOCHS = 50\n",
    "\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for X_train_batch, y_train_batch in train_loader:\n",
    "    X_train_batch, y_train_batch = X_train_batch, y_train_batch\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_train_pred = model(X_train_batch)\n",
    "\n",
    "    train_loss = criterion(y_train_pred, y_train_batch)\n",
    "    train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_epoch_loss += train_loss.item()\n",
    "    train_epoch_acc += train_acc.item()\n",
    "\n",
    "# VALIDATION    \n",
    "with torch.no_grad():\n",
    "\n",
    "    val_epoch_loss = 0\n",
    "    val_epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    for X_val_batch, y_val_batch in val_loader:\n",
    "        X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "\n",
    "        y_val_pred = model(X_val_batch)\n",
    "\n",
    "        val_loss = criterion(y_val_pred, y_val_batch)\n",
    "        val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "\n",
    "        val_epoch_loss += val_loss.item()\n",
    "        val_epoch_acc += val_acc.item()\n",
    "                \n",
    "loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                              \n",
    "    \n",
    "print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
